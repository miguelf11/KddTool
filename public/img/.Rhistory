install.packages("sparklyr")
install.packages("dplyr")
install.packages("ggplot2")
spark_available_versions()
library(sparklyr)
library(sparklyr)
install.packages("sparklyr")
install.packages("sparklyr")
install.packages("curl")
install.packages("curl")
install.packages("sparklyr")
library(sparklyr)
spark_available_versions()
spark_install(version = "2.1.0", hadoop_version = "2.7")
library(sparklyr)
sc <- spark_connect(master = "local")
spark_installed_versions()
spark_uninstall(2.1.0,2.7)
spark_uninstall("2.1.0","2.7")
spark_installed_versions()
spark_install(version = "2.1.0", hadoop_version = "2.7")
sc <- spark_connect(master = "local")
spark_installed_versions()
spark_uninstall("2.1.0","2.7")
spark_install(version = "2.1.0", hadoop_version = "2.7")
sc <- spark_connect(master = "local")
sc <- spark_connect(master = "local")
Sys.getenv("JAVA_HOME")
Sys.getenv("JAVA_HOME")
Sys.getenv("JAVA_HOME")
Sys.getenv("JAVA_HOME","/usr/local/jdk1.8.0_131")
Sys.getenv("JAVA_HOME")
Sys.setenv("JAVA_HOME","/usr/local/jdk1.8.0_131")
Sys.setenv("JAVA_HOME" = "/usr/local/jdk1.8.0_131")
Sys.getenv("JAVA_HOME")
sc <- spark_connect(master = "local")
install.packages(c("nycflights13", "Lahman"))
iris_tbl <- copy_to(sc, iris)
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
src_tbls(sc)
sc <- spark_connect(master = "local",spark_home = '/usr/local/spark/')
spark_disconnect_all()
sc <- spark_connect(master = "local",spark_home = '/usr/local/spark/')
sc <- spark_connect(master = "local")
import_iris <- copy_to(sc, iris, "spark_iris", overwrite = TRUE)
sc <- spark_connect(master = "local")
import_iris <- copy_to(sc, iris, "spark_iris", overwrite = TRUE)
partition_iris <- sdf_partition(import_iris,training=0.5, testing=0.5)
src_tbls(sc)
flights_tbl %>% filter(dep_delay == 2)
iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
flights_tbl %>% filter(dep_delay == 2)
flights_tbl %>% filter(dep_delay == 2)
sc <- spark_connect(master = "local")
import_iris <- copy_to(sc, iris, "spark_iris", overwrite = TRUE)
partition_iris <- sdf_partition(import_iris,training=0.5, testing=0.5)
library(dplyr)
library(sparklyr)
library(dplyr)
sc <- spark_connect(master = "local")
iris_tbl <- copy_to(sc, iris)
spark_disconnect_all()
sc <- spark_connect(master = "local")
iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
src_tbls(sc)
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
src_tbls(sc)
delay <- flights_tbl %>%
group_by(tailnum) %>%
summarise(count = n(), dist = mean(distance), delay = mean(arr_delay)) %>%
filter(count > 20, dist < 2000, !is.na(delay)) %>%
collect
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area(max_size = 2)
require("Rserve")
install.packages("Rserve")
library(sparklyr)
library(dplyr)
sc <- spark_connect(master = "local")
sc <- spark_connect(master = "local")
Sys.setenv("JAVA_HOME" = "/usr/local/jdk1.8.0_131")
sc <- spark_connect(master = "local")
iris_tbl <- copy_to(sc, iris)
iris_tbl <- copy_to(sc, iris)
spark_disconnect_all()
library(sparklyr)
library(dplyr)
Sys.setenv("JAVA_HOME" = "/usr/local/jdk1.8.0_131")
sc <- spark_connect(master = "local")
iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
spark_disconnect_all()
library(sparklyr)
library(dplyr)
sc <- spark_connect(master = "local")
require("RSclient")
install.packages("RSclient")
require("Rserve")
require("RSclient")
Rserve(args='--vanilla')
c <- RSconnect()
RSshutdown(c)
filename <- tempfile("plot2", fileext = ".png")
png(filename)
plot(1:10)
dev.off()
image <- readBin(filename, "raw", 29999)
unlink(filename)
image
X <- list()
X <- c(X, list(image))
X <- c(X, list(image))
X
toJSON(X)
require(RJSONIO)
library(sparklyr)
library(dplyr)
library(ggplot2)
toJSON(X)
toJSON(image)
typeof(image)
typeof(X)
toJSON(filename)
filename <- tempfile("plot2", fileext = ".png")
png(filename)
plot(1:10)
png(filename)
plot(1:10)
dev.off()
plot(1:10)
filename <- tempfile("plot2", fileext = ".png")
plot(1:10)
setwd("~/Escritorio/Restudio/json")
plot(1:10)
dev.off()
require(RJSONIO)
library(sparklyr)
library(dplyr)
library(ggplot2)
filename <- tempfile("plot2", fileext = ".png")
plot(1:10)
setwd("~/Escritorio/Restudio/json")
png(filename)
plot(1:10)
dev.off()
setwd("~/Escritorio/Restudio/json")
filename <- tempfile("plot2", fileext = ".png")
png(filename)
plot(1:10)
dev.off()
setwd("~/Escritorio/Restudio/json")
getwd()
png(filename="faithful.png")
plot(1:10)
dev.off()
setwd("/home/vit/meteor/KddTool/public/img")
png(filename="faithful.png")
plot(1:10)
print(p)
require(RJSONIO)
library(sparklyr)
library(dplyr)
library(ggplot2)
setwd("/home/vit/Escritorio/Restudio/json")
lista <- fromJSON("test.json")
setwd("/home/vit/meteor/KddTool/public/img")
Sys.setenv(HADOOP_HOME="/usr/local/hadoop")
Sys.setenv(JAVA_HOME="/usr/local/jdk1.8.0_131")
Sys.setenv(SPARK_HOME="/usr/local/spark")
sc <- spark_connect(master = "local")
ruta.base = "hdfs://127.0.1.1:40010"
for(i in lista ) {
if(i$label == "datos") {
ruta = paste(i$parametros[[1]][2])
ruta = paste(ruta.base,ruta,sep="")
print(paste("ruta: ",ruta))
import_data <- spark_read_csv(sc, name = "data", path = ruta, header = TRUE)
}
if(i$label == "split"){
print("Iniciosplit")
testing = i$parametros[[1]][2]
training = i$parametros[[2]][2]
partition_data <- sdf_partition(import_data,training=0.5, testing=0.5)
sdf_register(partition_data, c("spark_data_training","spark_data_test"))
print("Finsplit")
}
if(i$label == "seleccionar") {
print("Inicioseleccion")
features.select = i$properties
tidy_data <- tbl(sc,"spark_data_training") %>% select(one_of(features.select))
print("Finseleccion")
}
if(i$label == "arbol de decision"){
print("InicioArbol")
features = i$properties
model_data <- tidy_data %>% ml_decision_tree (response="Species", features=features)
print("FinArbol")
}
if(i$label == "comparar"){
print("InicioComparar")
test_data <- tbl(sc,"spark_data_test")
pred_data <- sdf_predict(model_data,  test_data) %>%collect
prediction <- pred_data$prediction
prediction <- data.frame(prediction)
colnames(prediction) <- "prediccion"
print("FinComparar")
}
if(i$label == "visualizar"){
png(filename="test.png")
p <- pred_data %>% inner_join(data.frame(prediction=0:2, lab=model_data$model.parameters$labels)) %>% ggplot(aes(PetalLength, PetalWidth, col=lab)) +geom_point()
print(p)
}
}
spark_disconnect_all()
require(RJSONIO)
library(sparklyr)
library(dplyr)
library(ggplot2)
setwd("/home/vit/Escritorio/Restudio/json")
lista <- fromJSON("test.json")
setwd("/home/vit/meteor/KddTool/public/img")
Sys.setenv(HADOOP_HOME="/usr/local/hadoop")
Sys.setenv(JAVA_HOME="/usr/local/jdk1.8.0_131")
Sys.setenv(SPARK_HOME="/usr/local/spark")
sc <- spark_connect(master = "local")
ruta.base = "hdfs://127.0.1.1:40010"
for(i in lista ) {
if(i$label == "datos") {
ruta = paste(i$parametros[[1]][2])
ruta = paste(ruta.base,ruta,sep="")
print(paste("ruta: ",ruta))
import_data <- spark_read_csv(sc, name = "data", path = ruta, header = TRUE)
}
if(i$label == "split"){
print("Iniciosplit")
testing = i$parametros[[1]][2]
training = i$parametros[[2]][2]
partition_data <- sdf_partition(import_data,training=0.5, testing=0.5)
sdf_register(partition_data, c("spark_data_training","spark_data_test"))
print("Finsplit")
}
if(i$label == "seleccionar") {
print("Inicioseleccion")
features.select = i$properties
tidy_data <- tbl(sc,"spark_data_training") %>% select(one_of(features.select))
print("Finseleccion")
}
if(i$label == "arbol de decision"){
print("InicioArbol")
features = i$properties
model_data <- tidy_data %>% ml_decision_tree (response="Species", features=features)
print("FinArbol")
}
if(i$label == "comparar"){
print("InicioComparar")
test_data <- tbl(sc,"spark_data_test")
pred_data <- sdf_predict(model_data,  test_data) %>%collect
prediction <- pred_data$prediction
prediction <- data.frame(prediction)
colnames(prediction) <- "prediccion"
print("FinComparar")
}
if(i$label == "visualizar"){
png(filename="testeo.png")
p <- pred_data %>% inner_join(data.frame(prediction=0:2, lab=model_data$model.parameters$labels)) %>% ggplot(aes(PetalLength, PetalWidth, col=lab)) +geom_point()
print(p)
}
}
spark_disconnect_all()
require(RJSONIO)
library(sparklyr)
library(dplyr)
library(ggplot2)
setwd("/home/vit/Escritorio/Restudio/json")
lista <- fromJSON("test.json")
setwd("/home/vit/meteor/KddTool/public/img")
Sys.setenv(HADOOP_HOME="/usr/local/hadoop")
Sys.setenv(JAVA_HOME="/usr/local/jdk1.8.0_131")
Sys.setenv(SPARK_HOME="/usr/local/spark")
sc <- spark_connect(master = "local")
ruta.base = "hdfs://127.0.1.1:40010"
for(i in lista ) {
if(i$label == "datos") {
ruta = paste(i$parametros[[1]][2])
ruta = paste(ruta.base,ruta,sep="")
print(paste("ruta: ",ruta))
import_data <- spark_read_csv(sc, name = "data", path = ruta, header = TRUE)
}
if(i$label == "split"){
print("Iniciosplit")
testing = i$parametros[[1]][2]
training = i$parametros[[2]][2]
partition_data <- sdf_partition(import_data,training=0.5, testing=0.5)
sdf_register(partition_data, c("spark_data_training","spark_data_test"))
print("Finsplit")
}
if(i$label == "seleccionar") {
print("Inicioseleccion")
features.select = i$properties
tidy_data <- tbl(sc,"spark_data_training") %>% select(one_of(features.select))
print("Finseleccion")
}
if(i$label == "arbol de decision"){
print("InicioArbol")
features = i$properties
model_data <- tidy_data %>% ml_decision_tree (response="Species", features=features)
print("FinArbol")
}
if(i$label == "comparar"){
print("InicioComparar")
test_data <- tbl(sc,"spark_data_test")
pred_data <- sdf_predict(model_data,  test_data) %>%collect
prediction <- pred_data$prediction
prediction <- data.frame(prediction)
colnames(prediction) <- "prediccion"
print("FinComparar")
}
if(i$label == "visualizar"){
png(filename="testeo.png", width = 480, height = 480)
p <- pred_data %>% inner_join(data.frame(prediction=0:2, lab=model_data$model.parameters$labels)) %>% ggplot(aes(PetalLength, PetalWidth, col=lab)) +geom_point()
print(p)
}
}
spark_disconnect_all()
require(RJSONIO)
library(sparklyr)
library(dplyr)
library(ggplot2)
setwd("/home/vit/Escritorio/Restudio/json")
lista <- fromJSON("test.json")
setwd("/home/vit/meteor/KddTool/public/img")
Sys.setenv(HADOOP_HOME="/usr/local/hadoop")
Sys.setenv(JAVA_HOME="/usr/local/jdk1.8.0_131")
Sys.setenv(SPARK_HOME="/usr/local/spark")
sc <- spark_connect(master = "local")
ruta.base = "hdfs://127.0.1.1:40010"
for(i in lista ) {
if(i$label == "datos") {
ruta = paste(i$parametros[[1]][2])
ruta = paste(ruta.base,ruta,sep="")
print(paste("ruta: ",ruta))
import_data <- spark_read_csv(sc, name = "data", path = ruta, header = TRUE)
}
if(i$label == "split"){
print("Iniciosplit")
testing = i$parametros[[1]][2]
training = i$parametros[[2]][2]
partition_data <- sdf_partition(import_data,training=0.5, testing=0.5)
sdf_register(partition_data, c("spark_data_training","spark_data_test"))
print("Finsplit")
}
if(i$label == "seleccionar") {
print("Inicioseleccion")
features.select = i$properties
tidy_data <- tbl(sc,"spark_data_training") %>% select(one_of(features.select))
print("Finseleccion")
}
if(i$label == "arbol de decision"){
print("InicioArbol")
features = i$properties
model_data <- tidy_data %>% ml_decision_tree (response="Species", features=features)
print("FinArbol")
}
if(i$label == "comparar"){
print("InicioComparar")
test_data <- tbl(sc,"spark_data_test")
pred_data <- sdf_predict(model_data,  test_data) %>%collect
prediction <- pred_data$prediction
prediction <- data.frame(prediction)
colnames(prediction) <- "prediccion"
print("FinComparar")
}
if(i$label == "visualizar"){
png(filename="testeo.png", width = 480, height = 480)
p <- pred_data %>% inner_join(data.frame(prediction=0:2, lab=model_data$model.parameters$labels)) %>% ggplot(aes(PetalLength, PetalWidth, col=lab)) +geom_point()
print(p)
dev.off()
}
}
spark_disconnect_all()
